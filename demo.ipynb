{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dacl-demo\n",
    "\n",
    "In this demo-notebook we will be importing a dacl model for the **Multi-Target Classification** of damage on reinforced concrete structures. \n",
    "All steps for feeding the dacl with tasty images of damage will be examined:\n",
    "\n",
    "1. ***Instantiate the dacl-model:*** First, the model must be instantiated by Dacl class. Currently there are three architectures available based on: ResNet 50, EfficientNet and MobileNetV3_large.\n",
    "2. ***Preprocess the image***: Before feeding the dacl-model we need to prepare the image. Our dacl models are very picky regarding his food.\n",
    "3. ***Feed the dacl-model***: Finally, feed the dacl-model with tasty preprocessed image data.\n",
    "4. ***Analyze the results***: Analyze the dacl-model's results and try to interpret them.\n",
    "\n",
    "\n",
    "## Imports\n",
    "Initially, we have to import the modules, we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import MemoryEfficientSwish\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate the dacl-model\n",
    "\n",
    "First, the model must be instantiated by Dacl class. Currently there are three architectures available based on: ResNet 50, EfficientNet and MobileNetV3_large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to find the suiting EfficientNet model according to the resolution of the input-images:\n",
    "efnet_dict = {'b0': 224, 'b1': 240, 'b2': 260, 'b3': 300,   \n",
    "              'b4': 380, 'b5': 456, 'b6': 528, 'b7': 600    \n",
    "             }\n",
    "\n",
    "class DaclNet(nn.Module):\n",
    "    def __init__(self, base_name, resolution, hidden_layers, num_class, drop_prob=0.2, freeze_base=True):\n",
    "        ''' Builds a network with a base model and a classifier with arbitrary hidden layers.\n",
    "        \n",
    "            Attributes\n",
    "            ---------\n",
    "            base_name: string, basemodel for the NN\n",
    "            resolution: resolution of the input-images, example: 224, 240...(look efnet_dic), Only needed for EfficientNet\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            drop_prob: float, dropout probability\n",
    "            freeze_base: boolean, choose if you want to freeze the parameters of the base model\n",
    "            num_class: integer, size of the output layer according to the number of classes\n",
    "\n",
    "            Example\n",
    "            ---------\n",
    "            model = Network(base_name='efficientnet', resolution=224, hidden_layers=[32,16], num_class=6, drop_prob=0.2, freeze_base=True)\n",
    "\n",
    "            Note\n",
    "            ---------\n",
    "            -print(efficientnet) -> Last module: (_swish): MemoryEfficientSwish() and the last fc-layers\n",
    "             Don't worry! Won't be called during forward due to: \"self.base.extract_features\"! No activation of last layer!\n",
    "        '''\n",
    "        super(DaclNet, self).__init__()\n",
    "        # basemodel\n",
    "        self.base_name = base_name\n",
    "        self.resolution = resolution\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.freeze_base = freeze_base\n",
    "        if self.base_name == 'mobilenet':\n",
    "            base = models.mobilenet_v3_large(pretrained=True)\n",
    "            modules = list(base.children())[:-1]\n",
    "            self.base = nn.Sequential(*modules)\n",
    "            if hidden_layers:\n",
    "                self.classifier = nn.ModuleList([nn.Linear(base.classifier[0].in_features, self.hidden_layers[0])]) #Input features = depth of the last BatchNorm layer = input features of first layer of original classifier\n",
    "            else:\n",
    "                self.classifier = nn.Linear(base.classifier[0].in_features, num_class)\n",
    "            self.activation = nn.Hardswish()\n",
    "\n",
    "        elif self.base_name == 'resnet':\n",
    "            base = models.resnet50(pretrained=True)\n",
    "            modules = list(base.children())[:-1]\n",
    "            self.base = nn.Sequential(*modules)\n",
    "            if self.hidden_layers:\n",
    "                self.classifier = nn.ModuleList([nn.Linear(base.fc.in_features, self.hidden_layers[0])])\n",
    "            else:\n",
    "                self.classifier = nn.Linear(base.fc.in_features, num_class)   \n",
    "            self.activation = nn.ELU()\n",
    "\n",
    "        elif self.base_name == 'efficientnet':      # Implementing Effnet the same way like the others didn't work, because omitting the last module also removes last batchnorm, avg-pooling\n",
    "            for ver in efnet_dict:\n",
    "                if efnet_dict[ver] == self.resolution:\n",
    "                    self.version = ver\n",
    "                    full_name = self.base_name+'-'+ver\n",
    "            self.base = EfficientNet.from_pretrained(model_name=full_name)\n",
    "            if self.hidden_layers:\n",
    "                self.classifier = nn.ModuleList([nn.Linear(self.base._fc.in_features, self.hidden_layers[0])])\n",
    "            else:\n",
    "                self.classifier = nn.Linear(self.base._fc.in_features, num_class)   \n",
    "            self.activation = MemoryEfficientSwish()\n",
    "        elif self.base_name == 'mobilenetv2':\n",
    "            base = models.mobilenet.mobilenet_v2(pretrained=True)\n",
    "            modules = list(base.children())[:-1]\n",
    "            self.base = nn.Sequential(*modules)\n",
    "            if hidden_layers:\n",
    "                self.classifier = nn.ModuleList([nn.Linear(base.classifier[1].in_features, self.hidden_layers[0])]) #Input features = depth of the last BatchNorm layer = input features of first layer of original classifier\n",
    "            else:\n",
    "                self.classifier = nn.Linear(base.classifier[1].in_features, num_class)\n",
    "            self.activation = nn.ReLU()\n",
    " \n",
    "        else:\n",
    "            raise NotImplementedError    \n",
    "        \n",
    "        # freeze the base\n",
    "        if self.freeze_base:\n",
    "            for param in self.base.parameters(): \n",
    "                param.requires_grad_(False)\n",
    "        \n",
    "        self.avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(p=drop_prob, inplace=True)\n",
    "\n",
    "        # classifier\n",
    "        # Add a variable number of more hidden layers\n",
    "        if self.hidden_layers:\n",
    "            layer_sizes = zip(self.hidden_layers[:-1], self.hidden_layers[1:])     \n",
    "            self.classifier.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "            # add output layer to classifier\n",
    "            self.classifier.append(nn.Linear(self.hidden_layers[-1], num_class))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        x = self.base(input_batch) if self.base_name != 'efficientnet' else self.base.extract_features(input_batch)\n",
    "        x = self.avg_pooling(x)\n",
    "        x = self.dropout(x)     \t# Only in EfficientNet a Dropout is aplied here, we tried it for all!  \n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.hidden_layers:    \n",
    "            for i,each in enumerate(self.classifier):\n",
    "                if i < len(self.classifier)-1:\n",
    "                    x = self.activation(each(x))\n",
    "                    x = self.dropout(x)\n",
    "                else:\n",
    "                    logits = each(x)\n",
    "                    break\n",
    "        else:\n",
    "            logits = self.classifier(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the image\n",
    "\n",
    "Before feeding the dacl-model we need to prepare the image. Our dacl models are very picky regarding their food.\n",
    "We have to get a image transformed to a tensor with the shape *N x C x H x W* where *N* is the batch-size, *C* the color channels (RGB), *H* the height and *W* the width of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing-function:\n",
    "def process_img(img_path=False):\n",
    "\t''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "\treturns a Torch Tensor\n",
    "\tArgs: \n",
    "\t\tfilepath: \tfilepath of the image (string)\n",
    "\t\t\tExample: 'test/1/image_06743.jpg'\n",
    "\tReturns: torch.float32 of shape: [1, 3, 224, 224]\n",
    "\t'''\n",
    "\n",
    "\tif not img_path:\n",
    "\t\tprint('Parse the filename of the image!')\n",
    "\telse:\n",
    "\t\t#Parse image as PIL Image\n",
    "\t\timage = Image.open(img_path)\n",
    "\t\t# Setting Resize Parameters (width and height)\n",
    "\t\timage_ratio = image.height / image.width\n",
    "\t\tif  image.width < image.height  or image.width > image.height:\n",
    "\t\t\tif image.width < image.height:\n",
    "\t\t\t\tresize = (256, int(image_ratio * 256))\n",
    "\t\t\telse:\n",
    "\t\t\t\tresize = (int(256 / image_ratio), 256)\n",
    "\t\telse:\n",
    "\t\t\tresize = (256, 256)\n",
    "\t\t\n",
    "\t\t#Setting Crop parameters\n",
    "\t\tcrop_size = 224\n",
    "\t\tcrop_x = int((resize[0] - crop_size) / 2)\n",
    "\t\tcrop_y = int((resize[1] - crop_size) / 2)\n",
    "\t\tcrop_box = (crop_x, crop_y,crop_x + crop_size, crop_y+crop_size)\n",
    "\t  \t\n",
    "\t\t#Transformation\n",
    "\t\tpil_image = image.resize(resize)\n",
    "\t\tpil_image = pil_image.crop(crop_box)\n",
    "\t\tnp_image = np.array(pil_image)\n",
    "\t\tnp_image = (np_image/255 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "\t\tnp_image = np_image.transpose(2,0,1)\n",
    "\t\timage = torch.from_numpy(np_image)\n",
    "\t\timage = image.unsqueeze_(0)\n",
    "\t\timage = image.type(torch.FloatTensor)\n",
    "\t\treturn image\n",
    "\n",
    "\n",
    "# Get image and show it:\n",
    "img = plt.imread('assets/11_008121.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Preprocess:\n",
    "img_proc = process_img('assets/11_008121.jpg')\n",
    "print(\"The datatype of the preprocessed image is: {} and it's shape is: {}\".format(img_proc.dtype, img_proc.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feed the dacl-model\n",
    "Finally, Load a checkpoint of your choice and feed the dacl-model with tasty preprocessed image data.\n",
    "\n",
    "**Choose a checkpoint from the table inside README!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which checkpoint/model you want to load from the table above:\n",
    "cp_name = 'McdsBikit_res_dacl.pth'\n",
    "\n",
    "cp = torch.load('models/' + cp_name) \n",
    "model = DaclNet(base_name=cp['base'], resolution = cp['resolution'], hidden_layers=cp['hidden_layers'], \n",
    "\t\t\t\tdrop_prob=cp['drop_prob'], num_class=cp['num_class'])\n",
    "model.load_state_dict(cp['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Now let's feed the dacl-model in order to  classify the image that we imported at the beginning:\n",
    "logits = model(img_proc)\n",
    "\n",
    "# Apply sigmoid activation to get predictions:\n",
    "preds = torch.sigmoid(logits).float()\n",
    "\n",
    "# Binarize results:\n",
    "threshold = .5 # Which threshold do you want to choose for binarization of predictions (for bikit .5 was chosen)\n",
    "bin = np.array(preds.squeeze(0) > threshold, dtype=float)\n",
    "\n",
    "# Here are our damage-class-names stored with the according position in the output vector:\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "\tcat_to_name = json.load(f)[cp['dataset']]\n",
    "\tprint('Position and name of class according to the order in the output cvector:\\n', cat_to_name)\n",
    "\n",
    "# Output:\n",
    "# print('This is the model you have just created:\\n', model)\n",
    "print('*'*10, 'Output', '*'*10)\n",
    "print('Predictions: ', preds)\n",
    "print('Binarized Output: ', bin)\n",
    "for i,r in enumerate(bin):\n",
    "\tif r != 0:\n",
    "\t\tprint(i, ': ', cat_to_name[str(i)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the results\n",
    "Analyze the dacl-model's results and try to interpret them. Here is planned to provide code for testing on test datasets from bikit."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be5efd023f3affc850b9d9dfb74d7430ce06302eaa9619162d325c43dbb5c06e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('hytu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
